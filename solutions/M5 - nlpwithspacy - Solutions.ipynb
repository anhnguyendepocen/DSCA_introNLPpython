{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 Spacy Exercise\n",
    "\n",
    "Import the Hep Dataset and using spacy perform the steps listed below to the text column. Add new columns to hold results of each operation\n",
    "\n",
    "\n",
    "        Tokenise\n",
    "        Identify all phrases in column that have the pattern - adjective/noun (only one instance in the text column)\n",
    "        Remove all stopwords\n",
    "        Remove all punctuation\n",
    "        Remove all numbers\n",
    "        Identify sentences\n",
    "        Lemmatize the text\n",
    "        Apply POS tagging\n",
    "        Apply shallow parsing\n",
    "        Apply Named Entity Recognition\n",
    "        Apply Dependency Parsing\n",
    "        \n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import stanza\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the language model instance in spaCy\n",
    "nlp = spacy.load('../pre_course/spacy/small_practice_model/en_core_web_sm-2.3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep = pd.read_pickle(\"../data/Hep_Dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to change text column to string\n",
    "def change_to_string(ptext):\n",
    "    return \" \".join(ptext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['Text'] = hep['Text'].apply(change_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep a copy of the df \n",
    "hep2 = hep.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_spacy(pdoc):\n",
    "    pdoc = nlp(pdoc)\n",
    "    return [token.text for token in pdoc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['token_spacy'] = hep['Text'].apply(token_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[2, 'token_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify all phrases in column that have the pattern - adjective/noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('../pre_course/spacy/small_practice_model/en_core_web_sm-2.3.1')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    hep.loc[5, 'Text']\n",
    "    )\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "def stopword_spacy(pdoc):\n",
    "    pdoc = nlp(pdoc)\n",
    "    text = \" \".join([str(token) for token in pdoc if not token.is_stop])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['preprocess_spacy'] = hep['Text'].apply(stopword_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'preprocess_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all punctuation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punctuation_spacy(pdoc):\n",
    "    pdoc = nlp(pdoc)\n",
    "    text = \"\"\n",
    "    for token in pdoc:\n",
    "        if not token.is_punct:\n",
    "            text = text + \" \" + str(token)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['preprocess_spacy'] = hep['preprocess_spacy'].apply(punctuation_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'preprocess_spacy' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonumbers_spacy(pdoc):\n",
    "    pdoc = nlp(pdoc)\n",
    "    text = \"\"\n",
    "    for token in pdoc:\n",
    "        if token.is_alpha:\n",
    "            text = text + \" \" + str(token)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['preprocess_spacy'] = hep['preprocess_spacy'].apply(nonumbers_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'preprocess_spacy' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nlp(\"There is a green hill far away. It is in a land I heard in a lullaby\")\n",
    "sentences = list(text.sents)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence, type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_spacy(pdoc):\n",
    "    pdoc = nlp(pdoc)\n",
    "    psentences = list(pdoc.sents)\n",
    "    return [sentence for sentence in psentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['sentence_spacy'] = hep['Text'].apply(sentence_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'sentence_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize the text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization_spacy(pdoc):\n",
    "    \n",
    "    pdoc =  nlp(pdoc)\n",
    "    text  = \"\"\n",
    "    \n",
    "    for token in pdoc:\n",
    "        text = text + \" \" + str(token.lemma_)\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['preprocess_spacy'] = hep['preprocess_spacy'].apply(lemmatization_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'preprocess_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply POS tagging   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_spacy(pdoc):\n",
    "    \n",
    "    pdoc = nlp(pdoc)\n",
    "    pos = []\n",
    "    \n",
    "    for token in pdoc:\n",
    "        pos.append([token.text, \"-->\", token.pos_])\n",
    " \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['pos_spacy'] = hep['Text'].apply(pos_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'pos_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply shallow parsing\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nounchunk_spacy(pdoc):\n",
    "    \n",
    "    pdoc =  nlp(pdoc)\n",
    "    noun_chunks  = []\n",
    "    \n",
    "    for chunk in pdoc.noun_chunks:\n",
    "        noun_chunks.append(chunk)\n",
    "        \n",
    "    return noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['noun_chunks_spacy'] = hep['Text'].apply(nounchunk_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5,'noun_chunks_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Named Entity Recognition\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ne_spacy(pdoc):\n",
    "    \n",
    "    pdoc =  nlp(pdoc)\n",
    "    named_entities  = []\n",
    "    \n",
    "    for entity in pdoc.ents:\n",
    "        named_entities.append([entity.text, \"--->\", entity.label_] )\n",
    "        \n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['ne_spacy'] = hep['Text'].apply(ne_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep.loc[5, 'ne_spacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depend_parse_spacy(pdoc):\n",
    "    \n",
    "    pdoc =  nlp(pdoc)\n",
    "    de_parse  = []\n",
    "    \n",
    "    for token in pdoc:\n",
    "        de_parse.append([token.text, \"--->\", token.dep_])\n",
    "        \n",
    "    return de_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep['de_parse_spacy'] = hep['Text'].apply(depend_parse_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.loc[5, 'de_parse_spacy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
