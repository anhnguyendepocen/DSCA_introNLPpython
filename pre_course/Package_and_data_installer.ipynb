{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to NLP Packages and Data\n",
    "\n",
    "Notebook to allow participants to install all required packages and data downloads before the course begins.\n",
    "\n",
    "It is recommended that participants use a virtual environment for managing packages. For more information on how to do this:\n",
    "\n",
    "[Here for working with venv](https://docs.python.org/3/library/venv.html)\n",
    "\n",
    "[And here for getting it to work with jupyter notebooks](https://janakiev.com/blog/jupyter-virtual-envs/)\n",
    "\n",
    "This course uses a range of domain specific libraries, unfortunately some of these are challenging to use with secure devices. Where possible work arounds have been provided in this course - however the best advice is to consult your home department's package guidance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Dependencies\n",
    "\n",
    "By `pip` installing requirements.txt we can have all the required packages for the course ready to go.\n",
    "\n",
    "**Use the command below in your Anaconda Prompt, or where you install packages**\n",
    "This will need to be done from the same working directory as this notebook, or point to the location of \"requirements.txt\".\n",
    "\n",
    "**WARNING** Some packages are large and may take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\users\\leyshr\\onedrive' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# The below code will install all the required versions of packages to your **current** kernel\n",
    "# only try if the above does not work\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\users\\leyshr\\onedrive' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# install NLTK if it is not already\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP data from packages\n",
    "\n",
    "Some packages require specific data in order to achieve their full functionality. Note the below will not work on an ONS network device, please use the binder version of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c8d00af35e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run this block if you do not want to install the data yourself (off network)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./nltk_data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# test it works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Run this block if you do not want to install the data yourself (off network)\n",
    "import nltk\n",
    "nltk.data.path.append('./nltk_data/')\n",
    "\n",
    "# test it works\n",
    "from nltk import word_tokenize\n",
    "\n",
    "word_tokenize(\"My name is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this block if you would like to install the data onto your machine\n",
    "import nltk\n",
    "\n",
    "required_downloads = ['tokenizers/punkt', 'corpora/wordnet', 'corpora/stopwords',\n",
    "                      'taggers/averaged_perceptron_tagger', 'chunkers/maxent_ne_chunker',\n",
    "                      'corpora/words']\n",
    "\n",
    "for asset_name in required_downloads:\n",
    "    name = asset_name.split(\"/\")[1]\n",
    "    try:\n",
    "        nltk.data.find(asset_name)\n",
    "    except LookupError:\n",
    "        nltk.download(name)\n",
    "\n",
    "# test it works\n",
    "from nltk import word_tokenize\n",
    "\n",
    "word_tokenize(\"My name is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install spacy model\n",
    "\n",
    "The spacy model used cannot often be installed with the `requirements.txt` file. Running the code below will allow it to be imported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run if package not installed\n",
    "#!{sys.executable} -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small model has been pre-installed within this repository, if you cannot download it yourself then the path to the model will be given throughout the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will not work on a closed network system\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanza Model\n",
    "\n",
    "**WARNING** This model, used twice in the course is ~500MB in size.\n",
    "\n",
    "Whilst `stanza` is a powerful and useful models - it's downloads and required packages are not necessarily supported on all systems. The core concepts in this course are taught without it - but stanza models are included where appropriate. If you cannot get the model download to work - that is okay and will not significantly reduce your experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run if package not installed\n",
    "#!{sys.executable} -m pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below will only work if your network allows\n",
    "stanza.download('en') # download English model for neural pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"./spacy/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intronlpenv",
   "language": "python",
   "name": "intronlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
